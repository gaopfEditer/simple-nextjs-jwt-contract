# visits 表大数据量优化方案

## 问题分析

### 当前问题
1. **全表扫描**：`COUNT(*)` 和 `COUNT(DISTINCT visitor_id)` 需要扫描全表
2. **SELECT ***：查询所有字段，包括 TEXT 类型的大字段（user_agent, referer, query_string）
3. **无时间范围限制**：查询可能扫描所有历史数据
4. **无分页机制**：只能通过 LIMIT，无法高效翻页
5. **数据无限增长**：没有归档机制，表会越来越大

### 数据量预估
- 假设每天 10,000 次访问
- 1年 = 365万条记录
- 5年 = 1825万条记录
- 单条记录约 500-1000 字节
- 5年数据约 9-18GB

## 优化方案

### 1. 索引优化 ⭐⭐⭐⭐⭐
**优先级：最高**

#### 当前索引
- `idx_site_created` (site_id, created_at) - 已有，但需要优化顺序

#### 优化建议
```sql
-- 优化复合索引顺序（先时间后站点，支持时间范围查询）
ALTER TABLE visits DROP INDEX idx_site_created;
CREATE INDEX idx_created_site ON visits(created_at DESC, site_id);

-- 添加覆盖索引（减少回表）
CREATE INDEX idx_visit_list ON visits(site_id, created_at DESC, id, ip_address, device_type, browser, os, path);
```

**效果**：查询速度提升 10-100 倍

---

### 2. 字段选择优化 ⭐⭐⭐⭐
**优先级：高**

#### 问题
- `SELECT *` 会读取所有字段，包括 TEXT 类型（user_agent, referer, query_string）
- 这些字段可能很大，但列表查询通常不需要

#### 优化
```sql
-- 列表查询只选择必要字段
SELECT id, site_id, ip_address, device_type, browser, os, path, created_at
FROM visits 
WHERE site_id = ? AND created_at >= ?
ORDER BY created_at DESC 
LIMIT 50;
```

**效果**：减少 50-80% 的数据传输量

---

### 3. 时间范围限制 ⭐⭐⭐⭐⭐
**优先级：最高**

#### 问题
- 查询可能扫描所有历史数据
- 用户通常只关心最近的数据

#### 优化
- 默认只查询最近 30 天
- 提供可选的时间范围参数
- 使用 `created_at >= DATE_SUB(NOW(), INTERVAL 30 DAY)`

**效果**：查询数据量减少 90%+

---

### 4. 游标分页 ⭐⭐⭐⭐
**优先级：高**

#### 问题
- `LIMIT offset, count` 在 offset 很大时性能极差
- 例如：`LIMIT 100000, 50` 需要扫描 100050 行

#### 优化
- 使用基于 ID 或时间戳的游标分页
- `WHERE id > last_id ORDER BY id LIMIT 50`
- 或 `WHERE created_at < last_time ORDER BY created_at DESC LIMIT 50`

**效果**：翻页性能提升 100-1000 倍

---

### 5. 统计表预计算 ⭐⭐⭐⭐
**优先级：高**

#### 问题
- `COUNT(*)` 和 `COUNT(DISTINCT visitor_id)` 需要全表扫描
- 每次查询都要重新计算

#### 优化
- 创建 `visits_daily_stats` 表，按天汇总
- 每小时或每天更新一次
- 查询时从汇总表读取，只需汇总最近几天的数据

**效果**：统计查询速度提升 1000+ 倍

---

### 6. 数据归档 ⭐⭐⭐
**优先级：中**

#### 问题
- 历史数据占用大量空间
- 影响查询性能

#### 优化
- 创建 `visits_archive` 表（结构相同）
- 定期将 90 天前的数据移到归档表
- 归档表可以压缩存储或使用 MyISAM

**效果**：主表数据量减少 70%+

---

### 7. 表分区 ⭐⭐⭐
**优先级：中**

#### 问题
- 单表数据量过大
- 删除旧数据困难

#### 优化
- 按月份分区：`PARTITION BY RANGE (YEAR(created_at) * 100 + MONTH(created_at))`
- 可以快速删除整个分区
- 查询时自动分区裁剪

**效果**：维护效率提升，查询性能提升 20-50%

---

### 8. 缓存策略 ⭐⭐⭐
**优先级：中**

#### 问题
- 统计数据频繁查询
- 每次都要访问数据库

#### 优化
- 使用 Redis 缓存统计数据
- 缓存时间：5-10 分钟
- 数据更新时清除缓存

**效果**：减少数据库压力 80%+

---

### 9. 异步写入 ⭐⭐
**优先级：低**

#### 问题
- 每次访问都要写入数据库
- 高并发时可能成为瓶颈

#### 优化
- 使用消息队列（Redis Queue）
- 批量写入（每 100 条或每 5 秒）
- 降低数据库写入压力

**效果**：写入性能提升 10-50 倍

---

## 实施优先级

### 第一阶段（立即实施）
1. ✅ 索引优化
2. ✅ 字段选择优化
3. ✅ 时间范围限制
4. ✅ 游标分页

### 第二阶段（1-2周内）
5. ✅ 统计表预计算
6. ✅ 缓存策略

### 第三阶段（1个月内）
7. ✅ 数据归档
8. ✅ 表分区（可选）

### 第四阶段（长期）
9. ✅ 异步写入（如果写入成为瓶颈）

---

## 预期效果

### 查询性能
- 列表查询：从 5-10 秒 → 50-200 毫秒
- 统计查询：从 10-30 秒 → 10-50 毫秒
- 翻页性能：从不可用 → 50-200 毫秒

### 存储优化
- 主表数据量：减少 70%+
- 查询数据量：减少 90%+

### 系统负载
- 数据库 CPU：降低 60-80%
- 数据库 IO：降低 70-90%
- 内存使用：优化 50%+

